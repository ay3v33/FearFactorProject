{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2616e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apvan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers datasets\n",
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None,\n",
    "    device=0        # use GPU 0\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d9aed",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/testscommunity_safety_initiative.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/tests\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/tests\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     10\u001b[0m             data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;66;03m# Use filename without extension as key\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/testscommunity_safety_initiative.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Dictionary to hold all loaded texts\n",
    "texts = {}\n",
    "\n",
    "for filename in os.listdir(\"../data/tests\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(\"../data/tests/\" + filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            # Use filename without extension as key\n",
    "            key_base = os.path.splitext(filename)[0]\n",
    "                \n",
    "            # Save all keys from the JSON file (like 'text', 'reference_text') inside a sub-dictionary\n",
    "            texts[key_base] = data.copy()\n",
    "\n",
    "# Example access\n",
    "print(texts[\"drones_of_deception_temple\"][\"text\"])\n",
    "print(texts[\"cyber_attack_killeen_power_plant\"][\"reference_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc80946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Expected Results:\n",
      "{'fear': 3, 'stress': 3, 'morale': 1, 'trust_in_authorities': 1}\n"
     ]
    }
   ],
   "source": [
    "# The directory where your expected output files are stored\n",
    "expected_outputs_dir = \"../data/expected_outputs\"\n",
    "\n",
    "# A dictionary to hold the expected results\n",
    "expected_results = {}\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.isdir(expected_outputs_dir):\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(expected_outputs_dir):\n",
    "        # Process only JSON files\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(expected_outputs_dir, filename)\n",
    "            # Use the filename without the .json extension as the key\n",
    "            key = os.path.splitext(filename)[0]\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                # Load the JSON data and add it to the dictionary\n",
    "                expected_results[key] = json.load(f)\n",
    "\n",
    "# Print the resulting dictionary (optional, for verification)\n",
    "print(\"Loaded Expected Results:\")\n",
    "print(expected_results[\"drones_of_deception_temple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86d37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def chunk_text(text, tokenizer, max_tokens=400):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n",
    "    return [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "\n",
    "def avg_emotion_scores(text, classifier, tokenizer):\n",
    "    if (len(tokenizer.encode(text)) <= 400):\n",
    "        result = classifier(text)[0]\n",
    "        return {item['label']: item['score'] for item in result}\n",
    "\n",
    "    chunks = chunk_text(text, tokenizer)\n",
    "    cumulative_scores = defaultdict(float)\n",
    "    total_chars = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        result = classifier(chunk)[0]\n",
    "        chunk_len = len(chunk)\n",
    "        total_chars += chunk_len\n",
    "        for item in result:\n",
    "            cumulative_scores[item['label']] += item['score'] * chunk_len\n",
    "\n",
    "    averaged_scores = {label: score / total_chars for label, score in cumulative_scores.items()}\n",
    "    return averaged_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e3eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drones_of_deception_temple:  {'fear': 0.7602706353398871, 'anger': 0.10429053363751974, 'neutral': 0.1027084575187392, 'disgust': 0.014090057810052512, 'sadness': 0.010059505021061598, 'surprise': 0.006131273001968546, 'joy': 0.0024495590180118303}\n",
      "cyber_attack_killeen_power_plant:  {'fear': 0.5403466023699296, 'neutral': 0.313806427239273, 'surprise': 0.05438798490393844, 'sadness': 0.042338932968801986, 'anger': 0.0365296998182841, 'disgust': 0.009242527178286957, 'joy': 0.0033478991274425787}\n",
      "food_shortage_rumors:  {'disgust': 0.43370577692985535, 'anger': 0.2831280827522278, 'neutral': 0.11049191653728485, 'surprise': 0.07179553806781769, 'sadness': 0.06034587323665619, 'fear': 0.03899148479104042, 'joy': 0.0015412700595334172}\n",
      "nato_exercises_boost_confidence:  {'fear': 0.4742882251739502, 'joy': 0.2648555338382721, 'neutral': 0.21620242297649384, 'anger': 0.020228777080774307, 'disgust': 0.011500043794512749, 'sadness': 0.006775944493710995, 'surprise': 0.006148991174995899}\n",
      "virus_panic_harker_heights:  {'fear': 0.8213873505592346, 'neutral': 0.10423986613750458, 'surprise': 0.02420601062476635, 'disgust': 0.019223535433411598, 'anger': 0.017785385251045227, 'sadness': 0.011757107451558113, 'joy': 0.0014007784193381667}\n",
      "factory_explosion_false_flag:  {'neutral': 0.3301582634449005, 'anger': 0.299518346786499, 'fear': 0.19576232135295868, 'disgust': 0.13269202411174774, 'surprise': 0.028090300038456917, 'sadness': 0.011250977404415607, 'joy': 0.002527702134102583}\n",
      "community_safety_initiative:  {'neutral': 0.8669243454933167, 'fear': 0.05165528878569603, 'joy': 0.040705595165491104, 'anger': 0.016247881576418877, 'surprise': 0.01307170931249857, 'disgust': 0.006921841762959957, 'sadness': 0.004473326727747917}\n"
     ]
    }
   ],
   "source": [
    "drones_of_deception_temple_results = avg_emotion_scores(texts[\"drones_of_deception_temple\"][\"text\"], classifier, tokenizer)\n",
    "print(\"drones_of_deception_temple: \", drones_of_deception_temple_results)\n",
    "\n",
    "cyber_attack_killeen_power_plant_results = avg_emotion_scores(texts[\"cyber_attack_killeen_power_plant\"][\"reference_text\"], classifier, tokenizer)\n",
    "print(\"cyber_attack_killeen_power_plant: \", cyber_attack_killeen_power_plant_results)\n",
    "\n",
    "food_shortage_rumors_results = avg_emotion_scores(texts[\"food_shortage_rumors\"][\"reference_text\"], classifier, tokenizer)\n",
    "print(\"food_shortage_rumors: \", food_shortage_rumors_results)\n",
    "\n",
    "nato_exercises_boost_confidence_results = avg_emotion_scores(texts[\"nato_exercises_boost_confidence\"][\"reference_text\"], classifier, tokenizer)\n",
    "print(\"nato_exercises_boost_confidence: \", nato_exercises_boost_confidence_results)\n",
    "\n",
    "virus_panic_harker_heights_results = avg_emotion_scores(texts[\"virus_panic_harker_heights\"][\"text\"], classifier, tokenizer)\n",
    "print(\"virus_panic_harker_heights: \", virus_panic_harker_heights_results)\n",
    "\n",
    "factory_explosion_false_flag_results = avg_emotion_scores(texts[\"factory_explosion_false_flag\"][\"reference_text\"], classifier, tokenizer)\n",
    "print(\"factory_explosion_false_flag: \", factory_explosion_false_flag_results)\n",
    "\n",
    "community_safety_initiative_results = avg_emotion_scores(texts[\"community_safety_initiative\"][\"text\"], classifier, tokenizer)\n",
    "print(\"community_safety_initiative: \", community_safety_initiative_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f661e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "# Clamps emotions to [-1, 1]\n",
    "def clamp(emotions: Dict[str, float]) -> Dict[str, float]:\n",
    "    for emotion in emotions:\n",
    "        if emotions[emotion] < -1:\n",
    "            emotions[emotion] = -1\n",
    "        elif emotions[emotion] > 1:\n",
    "            emotions[emotion] = 1\n",
    "    return emotions\n",
    "\n",
    "# Map emotions to fear, stress, trust and morale\n",
    "def emotions_to_fsmt(emotions: Dict[str, float]) -> Dict[str, int]:\n",
    "    fear = emotions.get(\"fear\")\n",
    "    anger = emotions.get(\"anger\")\n",
    "    neutral = emotions.get(\"neutral\")\n",
    "    disgust = emotions.get(\"disgust\")\n",
    "    sadness = emotions.get(\"sadness\")\n",
    "    joy = emotions.get(\"joy\")\n",
    "\n",
    "    fsmt_dict = {}\n",
    "    \n",
    "    if(fear > anger + neutral + disgust + sadness + joy or fear > 0.8):\n",
    "        fsmt_dict[\"Fear Level\"] = 3\n",
    "    elif(fear > 0.5 or fear > joy + neutral):\n",
    "        fsmt_dict[\"Fear Level\"] = 2\n",
    "    else:\n",
    "        fsmt_dict[\"Fear Level\"] = 1\n",
    "\n",
    "    if(sadness + anger > joy + neutral or fsmt_dict[\"Fear Level\"] == 3):\n",
    "        fsmt_dict[\"Stress Level\"] = 3\n",
    "    elif(sadness + anger > 0.5 or fsmt_dict[\"Fear Level\"] == 2):\n",
    "        fsmt_dict[\"Stress Level\"] = 2\n",
    "    else:\n",
    "        fsmt_dict[\"Stress Level\"] = 1\n",
    "\n",
    "    if(sadness + disgust + fear < neutral + joy):\n",
    "        fsmt_dict[\"Morale Level\"] = 3\n",
    "    elif(joy + neutral > 0.5):\n",
    "        fsmt_dict[\"Morale Level\"] = 2\n",
    "    else:\n",
    "        fsmt_dict[\"Morale Level\"] = 1\n",
    "\n",
    "    if(sadness + disgust + fear < joy):\n",
    "        fsmt_dict[\"Trust Level\"] = 3\n",
    "    elif(joy + neutral > sadness + disgust + fear):\n",
    "        fsmt_dict[\"Trust Level\"] = 2\n",
    "    else:\n",
    "        fsmt_dict[\"Trust Level\"] = 1\n",
    "\n",
    "    return fsmt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285f56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drones_of_deception_temple {'Fear Level': 3, 'Stress Level': 3, 'Morale Level': 1, 'Trust Level': 1}\n",
      "Expected:  {'fear': 3, 'stress': 3, 'morale': 1, 'trust_in_authorities': 1}\n",
      "\n",
      "\n",
      "cyber_attack_killeen_power_plant {'Fear Level': 3, 'Stress Level': 3, 'Morale Level': 1, 'Trust Level': 1}\n",
      "Expected:  {'fear': 3, 'stress': 3, 'morale': 1, 'trust_in_authorities': 2}\n",
      "\n",
      "\n",
      "food_shortage_rumors {'Fear Level': 1, 'Stress Level': 3, 'Morale Level': 1, 'Trust Level': 1}\n",
      "Expected:  {'fear': 3, 'stress': 3, 'morale': 1, 'trust_in_authorities': 1}\n",
      "\n",
      "\n",
      "nato_exercises_boost_confidence {'Fear Level': 1, 'Stress Level': 1, 'Morale Level': 1, 'Trust Level': 1}\n",
      "Expected:  {'fear': 1, 'stress': 1, 'morale': 3, 'trust_in_authorities': 3}\n",
      "\n",
      "\n",
      "virus_panic_harker_heights {'Fear Level': 3, 'Stress Level': 3, 'Morale Level': 1, 'Trust Level': 1}\n",
      "Expected:  {'fear': 3, 'stress': 3, 'morale': 1, 'trust_in_authorities': 1}\n",
      "\n",
      "\n",
      "factory_explosion_false_flag {'Fear Level': 1, 'Stress Level': 1, 'Morale Level': 1, 'Trust Level': 1}\n",
      "Expected:  {'fear': 3, 'stress': 3, 'morale': 1, 'trust_in_authorities': 1}\n",
      "\n",
      "\n",
      "community_safety_initiative {'Fear Level': 1, 'Stress Level': 1, 'Morale Level': 3, 'Trust Level': 2}\n",
      "Expected:  {'fear': 1, 'stress': 1, 'morale': 2, 'trust_in_authorities': 2}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('drones_of_deception_temple',emotions_to_fsmt(drones_of_deception_temple_results))\n",
    "print(\"Expected: \", expected_results[\"drones_of_deception_temple\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('cyber_attack_killeen_power_plant',emotions_to_fsmt(cyber_attack_killeen_power_plant_results))\n",
    "print(\"Expected: \", expected_results[\"cyber_attack_killeen_power_plant\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('food_shortage_rumors',emotions_to_fsmt(food_shortage_rumors_results))\n",
    "print(\"Expected: \", expected_results[\"food_shortage_rumors\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('nato_exercises_boost_confidence',emotions_to_fsmt(nato_exercises_boost_confidence_results))\n",
    "print(\"Expected: \", expected_results[\"nato_exercises_boost_confidence\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('virus_panic_harker_heights',emotions_to_fsmt(virus_panic_harker_heights_results))\n",
    "print(\"Expected: \", expected_results[\"virus_panic_harker_heights\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('factory_explosion_false_flag',emotions_to_fsmt(factory_explosion_false_flag_results))\n",
    "print(\"Expected: \", expected_results[\"factory_explosion_false_flag\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print('community_safety_initiative',emotions_to_fsmt(community_safety_initiative_results))\n",
    "print(\"Expected: \", expected_results[\"community_safety_initiative\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concerned about all the NATO convoys rolling through Temple, TX lately. What's the real reason for\n",
      "these moves? Are we preparing for another economic downturn? Local leaders need to address this if\n",
      "they want to keep their promises about increasing security & affordable living\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_short = pd.read_json(\"../data/MILDEC_short_out.jsonl\", lines=True)\n",
    "short_texts = df_short[\"text\"].tolist()\n",
    "\n",
    "df_long = pd.read_json(\"../data/MILDEC_long_out.jsonl\", lines=True)\n",
    "long_texts = df_long[\"text\"].tolist()\n",
    "\n",
    "#import textwrap\n",
    "#print(textwrap.fill(short_texts[800], width=100))\n",
    "\n",
    "short_text1 = short_texts[25]\n",
    "short_text2 = short_texts[100]\n",
    "short_text3 = short_texts[800]\n",
    "short_text4 = short_texts[1000]\n",
    "\n",
    "\n",
    "\n",
    "long_text1 = long_texts[30]\n",
    "long_text2 = long_texts[41]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d181d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some short tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29acfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some long tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
