{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2616e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers datasets\n",
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None,     # replaces return_all_scores=True\n",
    "    device=0        # use GPU 0\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "539d9aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As tensions between Donovia and the Western Bloc reach a boiling point, reports of mysterious drone sightings in Temple, Texas, have left residents on edge and sparked concerns about foreign interference in domestic affairs. Central Texas City Grapples with Mysterious Sightings Amidst Growing Tensions The Donovian government has issued a statement denying any involvement, but insiders claim otherwise. The situation is further complicated by the escalating global power struggle between Donovia an\n",
      "\n",
      "\n",
      "Killeen Cyber Attack Disrupts Local Power Plant. KILLEEN, TX â€“ On the morning of March 26th, the Killeen Power Plant experienced a cyber-attack that cut power to about 2,300 homes in Killeen. Operators detected unusual network activity at 4:00 a.m. and shut off four feeder circuits as a precaution. Workers are facilitating return of power and expect power to return at around 10:00am. What Happened Systems Hit: Main control server and backup communication lines. Impact: Widespread outages in four\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read files\n",
    "with open(\"../data/DocumentForParsing.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "dronesText = data1[\"text\"]\n",
    "\n",
    "with open(\"../data/DocumentForParsing2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "powerPlantAttackText = data2[\"reference_text\"]\n",
    "\n",
    "print(dronesText[:500])\n",
    "print(\"\\n\")\n",
    "print(powerPlantAttackText[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b86d37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_emotion_scores(text, tokenizer, classifier, chunk_size=None):\n",
    "    \"\"\"\n",
    "    Split `text` into token-sized chunks, run `classifier` on each chunk,\n",
    "    and return a dict of averaged label scores across all chunks.\n",
    "    \"\"\"\n",
    "    # choose chunk size (leave room for special tokens)\n",
    "    if chunk_size is None:\n",
    "        model_max = getattr(tokenizer, \"model_max_length\", 512)\n",
    "        chunk_size = max(2, model_max - 2)\n",
    "\n",
    "    # encode without special tokens then split into chunks of token ids\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    if len(input_ids) == 0:\n",
    "        return {}\n",
    "\n",
    "    token_chunks = [input_ids[i : i + chunk_size] for i in range(0, len(input_ids), chunk_size)]\n",
    "    # decode token chunks back to strings for the pipeline\n",
    "    text_chunks = [\n",
    "        tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for ids in token_chunks\n",
    "    ]\n",
    "\n",
    "    # classify all chunks at once; ensure truncation for safety\n",
    "    chunk_results = classifier(text_chunks, truncation=True, max_length=chunk_size)\n",
    "\n",
    "    # aggregate scores per label\n",
    "    sums = {}\n",
    "    counts = {}\n",
    "    for chunk_out in chunk_results:            # chunk_out is a list of {'label','score'} dicts\n",
    "        for item in chunk_out:\n",
    "            lbl = item[\"label\"]\n",
    "            sc = float(item[\"score\"])\n",
    "            sums[lbl] = sums.get(lbl, 0.0) + sc\n",
    "            counts[lbl] = counts.get(lbl, 0) + 1\n",
    "\n",
    "    # compute averages\n",
    "    avg_scores = {lbl: (sums[lbl] / counts[lbl]) for lbl in sums}\n",
    "    return avg_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9107ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDict(results):\n",
    "    return {item[\"label\"]: float(item[\"score\"]) for item in results[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17e3eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0.8270518183708191, 'anger': 0.08275649261971314, 'neutral': 0.0638207762191693, 'disgust': 0.010619757192519804, 'sadness': 0.008104392948249975, 'surprise': 0.005372426627824704, 'joy': 0.0022743274845803776}\n",
      "0.6234105825424194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dronesResults = avg_emotion_scores(dronesText, tokenizer, classifier)\n",
    "print(dronesResults)\n",
    "\n",
    "powerPlantAttackResults = convertToDict(classifier(powerPlantAttackText))\n",
    "print(powerPlantAttackResults[\"fear\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f661e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def clamp(x: float) -> float:\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "def emotions_to_fsmt(emotions: Dict[str, float], intensity: float = 0.5) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Convert emotion probabilities (0-1) to:\n",
    "      - fear\n",
    "      - stress\n",
    "      - morale\n",
    "      - trust\n",
    "    All outputs are clamped to [0,1].\n",
    "    Expected emotion keys: 'fear','anger','neutral','disgust','sadness','surprise','joy'.\n",
    "    \"\"\"\n",
    "    # ensure expected keys exist\n",
    "    keys = ['fear','anger','neutral','disgust','sadness','surprise','joy']\n",
    "    e = {k: float(emotions.get(k, 0.0)) for k in keys}\n",
    "    intensity = float(clamp(intensity))\n",
    "\n",
    "    # Fear: mostly the 'fear' signal, slightly boosted by surprise and anger when arousal is higher\n",
    "    fear = e['fear'] * (0.6 + 0.4 * intensity) + 0.2 * e['surprise'] + 0.1 * e['anger']\n",
    "\n",
    "    # Stress: combination of fear, anger and surprise; scaled by intensity and reduced by neutrality\n",
    "    stress_base = 0.6 * e['fear'] + 0.25 * e['anger'] + 0.15 * e['surprise']\n",
    "    stress = stress_base * (0.5 + 0.5 * intensity) + 0.1 * (1 - e['neutral'])\n",
    "\n",
    "    # Morale: increases with joy and neutral, decreases with negative emotions\n",
    "    negative = e['fear'] + e['anger'] + e['sadness'] + e['disgust']\n",
    "    positive = e['joy'] + 0.7 * e['neutral']\n",
    "    morale = (positive - 0.9 * negative) * (0.6 + 0.4 * (1 - intensity)) + 0.1\n",
    "\n",
    "    # Trust: boosted by neutral & joy, heavily reduced by fear/anger\n",
    "    trust = 0.5 * e['neutral'] + 0.6 * e['joy'] - 0.9 * (e['fear'] + e['anger']) + 0.2 * intensity\n",
    "\n",
    "    # clamp outputs to [0,1]\n",
    "    return {\n",
    "        'fear': clamp(fear),\n",
    "        'stress': clamp(stress),\n",
    "        'morale': clamp(morale),\n",
    "        'trust': clamp(trust)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "285f56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0.6709915892841917, 'stress': 0.4819124810067782, 'morale': 0.0, 'trust': 0.0}\n",
      "{'fear': 0.506616160646081, 'stress': 0.3625632446724921, 'morale': 0.0, 'trust': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(emotions_to_fsmt(dronesResults))\n",
    "print(emotions_to_fsmt(powerPlantAttackResults))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
